{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13651030",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8bb116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"C:/Users/jtqua/OneDrive/Desktop/INST414(0202) Data Science Techniques/capstone folder/2024_public_lar_csv/2024_public_lar_csv.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77593de",
   "metadata": {},
   "source": [
    "## Step 1: Inspect Dataset Structure\n",
    "This section loads only the header to check the number of columns and their names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82feae7",
   "metadata": {},
   "source": [
    "Check number of columns (by reading only the first line)\n",
    "Extremely fast and lightweight — reads only one line (the header).\n",
    "Doesn’t use pandas at all → no risk of memory overload.but It assumes commas (,) as the separator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa62ae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns in dataset: 99\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    header = f.readline()\n",
    "    num_columns = len(header.split(','))  # Assuming CSV is comma-separated\n",
    "print(f\"Total columns in dataset: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05971ac4",
   "metadata": {},
   "source": [
    "\n",
    "Safest and most accurate way to get exact column names.\n",
    " Automatically detects the delimiter (, / | / \\t, etc.) if your file is standard CSV.\n",
    " Returns names in the correct order, which helps when you’re planning analysis or debugging.\n",
    " Get column names without loading any data rows.\n",
    " This is fast and safe, and it avoids memory issues with very large CSVs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577012f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 99\n",
      "['activity_year', 'lei', 'derived_msa_md', 'state_code', 'county_code', 'census_tract', 'conforming_loan_limit', 'derived_loan_product_type', 'derived_dwelling_category', 'derived_ethnicity', 'derived_race', 'derived_sex', 'action_taken', 'purchaser_type', 'preapproval', 'loan_type', 'loan_purpose', 'lien_status', 'reverse_mortgage', 'open_end_line_of_credit', 'business_or_commercial_purpose', 'loan_amount', 'combined_loan_to_value_ratio', 'interest_rate', 'rate_spread', 'hoepa_status', 'total_loan_costs', 'total_points_and_fees', 'origination_charges', 'discount_points', 'lender_credits', 'loan_term', 'prepayment_penalty_term', 'intro_rate_period', 'negative_amortization', 'interest_only_payment', 'balloon_payment', 'other_nonamortizing_features', 'property_value', 'construction_method', 'occupancy_type', 'manufactured_home_secured_property_type', 'manufactured_home_land_property_interest', 'total_units', 'multifamily_affordable_units', 'income', 'debt_to_income_ratio', 'applicant_credit_score_type', 'co_applicant_credit_score_type', 'applicant_ethnicity_1', 'applicant_ethnicity_2', 'applicant_ethnicity_3', 'applicant_ethnicity_4', 'applicant_ethnicity_5', 'co_applicant_ethnicity_1', 'co_applicant_ethnicity_2', 'co_applicant_ethnicity_3', 'co_applicant_ethnicity_4', 'co_applicant_ethnicity_5', 'applicant_ethnicity_observed', 'co_applicant_ethnicity_observed', 'applicant_race_1', 'applicant_race_2', 'applicant_race_3', 'applicant_race_4', 'applicant_race_5', 'co_applicant_race_1', 'co_applicant_race_2', 'co_applicant_race_3', 'co_applicant_race_4', 'co_applicant_race_5', 'applicant_race_observed', 'co_applicant_race_observed', 'applicant_sex', 'co_applicant_sex', 'applicant_sex_observed', 'co_applicant_sex_observed', 'applicant_age', 'co_applicant_age', 'applicant_age_above_62', 'co_applicant_age_above_62', 'submission_of_application', 'initially_payable_to_institution', 'aus_1', 'aus_2', 'aus_3', 'aus_4', 'aus_5', 'denial_reason_1', 'denial_reason_2', 'denial_reason_3', 'denial_reason_4', 'tract_population', 'tract_minority_population_percent', 'ffiec_msa_md_median_family_income', 'tract_to_msa_income_percentage', 'tract_owner_occupied_units', 'tract_one_to_four_family_homes', 'tract_median_age_of_housing_units']\n"
     ]
    }
   ],
   "source": [
    "cols = pd.read_csv(file_path, nrows=0).columns\n",
    "print(f\"Number of columns: {len(cols)}\")\n",
    "print(cols.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1997c992",
   "metadata": {},
   "source": [
    " Count the total number of rows in a large dataset.\n",
    " Using pandas `.shape` would load the full dataset into memory, which can be too heavy for very large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1548da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 12,229,298\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    total_rows = sum(1 for line in f) - 1\n",
    "print(f\"Total rows in dataset: {total_rows:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
